\documentclass{article}
\usepackage{CJKutf8}
\usepackage{minted}
\usepackage{geometry}
\geometry{a4paper,centering,scale=0.8}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{float}
%可能用到的包
\title{Machine Learning - Week 5}
\author{赵燕}
\date{}
\begin{document} 
\hfuzz=\maxdimen
\tolerance=10000
\hbadness=10000
\begin{CJK}{UTF8}{gbsn} 
\maketitle
\renewcommand\contentsname{目录}
\renewcommand\figurename{图}
\tableofcontents
\newpage

\section{Cost Function and Backpropagation}
\subsection{Cost Function}
\subparagraph{}
首先引入一些便于稍后讨论的新标记方法：
\subparagraph{}
假设神经网络的训练样本有m个，每个包含一组输入x和输出信号y，L表示神经网络层数，$s_l$表示每层的neuron的个数，$s_L$表示最后一层中处理单元的个数。
\subparagraph{}
Let's first define a few variables that we will need to use:
\begin{itemize}
 \item L = total number of layers in the network
 \item $s_l$ = number of units (not counting bias unit) in layer l
 \item K = number of output units/classes
\end{itemize}
\subparagraph{}
将神经网络的分类定义为两种情况：二类分类和多类分类。
\subparagraph{}
二类分类（Binary classification）:
\begin{itemize}
  \item $s_L=1$，y= 0 or 1 ,表示哪一类；
  \item 1 output unit
\end{itemize}
\subparagraph{}
K类分类（Multi-class classification（K classes））：
\begin{itemize}
  \item $s_L=K$,$y_i=1$，表示分到第i类（$K\geqslant3$）;
  \item K output units
\end{itemize}
\begin{figure}[H]
\center{\includegraphics[width=.8\textwidth]{502.png}}
\caption{二类分类和K类分类}
\label{fig:502}
\end{figure}
\subparagraph{}
Recall that in neural networks, we may have many output nodes. We denote $h_\Theta{(x)}_k$ as being a hypothesis that results in the kth output. Our cost function for neural networks is going to be a generalization of the one we used for logistic regression.
\subparagraph{}
Recall that the cost function for regularized logistic regression was:
\begin{equation}
J(\theta)=-\frac{1}{m}\sum_{i=1}^m[y^{(i)}log(h_\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
\end{equation}
\subparagraph{}
在逻辑回归中，只有一个输出变量，又称标量（scalar），也只有一个因变量y，但是在神经网络中，可以有很多输出变量，$h_\Theta(x)$是一个K维度的向量，并且训练集中的因变量也是同样维度的一个向量，因此神经网络的代价函数会比逻辑回归更加复杂一些。
\subparagraph{}
For Neural Networks:
\begin{equation}
J(\Theta)=-\frac{1}{m}\sum_{i=1}^m\sum_{k=1}^K[y_k^{(i)}log((h_\Theta(x^{(i)}))_k)+(1-y_k^{(i)})log(1-(h_\Theta(x^{(i)}))_k)]+\frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_l+1}(\Theta_{j,i}^{(l)})^2
\end{equation}
\begin{figure}[H]
\center{\includegraphics[width=.8\textwidth]{503.png}}
\caption{逻辑回归和神经网络的代价函数}
\label{fig:503}
\end{figure}
\subparagraph{}
这个看起来复杂很多的代价函数背后的思想还是一样的，希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出K个预测，基本上可以利用循环，对每一行特征都预测K个不同的结果，然后利用循环在K个预测中选择可能性最高的一个，将其与y中的实际数据进行比较。
\subparagraph{}
正则化的那一项只是排除了每一层的$\Theta_0$后，每一层的$\Theta$矩阵的和，最里层的循环j循环所有的行（由$s_l+1$层的激活单元数决定），循环i则循环所有的列，由该层（$s_l$层）的激活单元数所决定。即：$h_\Theta(x)$与真实值之间的距离为每个样本，每个类输出的加和，对参数进行regularization的bias项处理所有参数的平方和。
\subparagraph{}
We have added a few nested summations to account for our multiple output nodes. In the first part of the equation, before the square brackets, we have an additional nested summation that loops through the number of output nodes.
\subparagraph{}
In the regularization part, after the square brackets, we must account for multiple theta matrices. The number of columns in our current theta matrix is equal to the number of nodes in our current layer (including the bias unit). The number of rows in our current theta matrix is equal to the number of nodes in the next layer (excluding the bias unit). As before with logistic regression, we square every term.
\subparagraph{}
Note:
\begin{itemize}
\item the double sum simply adds up the logistic regression costs calculated for each cell in the output layer
\item the triple sum simply adds up the squares of all the individual Θs in the entire network.
\item the i in the triple sum does not refer to training example i
\end{itemize}
\subsection{Backpropagation Algorithm}
\subparagraph{}
之前在计算神经网络预测结果时采用的是一种正向传播方法，从第一层开始正向一层一层进行计算，直到最后一层的$h_\Theta(x)$。
\subparagraph{}
现在，为了计算代价函数的偏导数$\frac{\partial}{\partial\Theta_{i,j}^{(l)}}J(\Theta)$，我们采用一种反向传播算法，也就是首先计算一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。
\subparagraph{}
举例说明反向传播算法：
\subparagraph{}
假设我们的训练集只有一个实例（$x^{(1)}$,$y^{(1)}$），我们的神经网络是一个四层的神经网络，其中 K=4，$S_L=4$，L=4：
\subparagraph{}
前向传播算法：
\begin{align}
a^{(1)} & =x \\
z^{(2)} & =\Theta^{(1)}a^{(1)} \\
a^{(2)} & =g(z^{(2)})(add\quad{a_0^{(2)}}) \\
z^{(3)} & =\Theta^{(2)}a^{(2)} \\
a^{(3)} & =g(z^{(3)})(add\quad{a_0^{(3)}}) \\
z^{(4)} & =\Theta^{(3)}a^{(3)} \\
a^{(4)} & =h_\Theta(x)=g(z^{(4)})
\end{align}
\begin{figure}[H]
\center{\includegraphics[width=.4\textwidth]{504.png}}
\caption{前向传播算法求激励函数}
\label{fig:504}
\end{figure}
计算偏导数项利用反向传播算法：Backpropagation Algorithm
\subparagraph{}
"Backpropagation" is neural-network terminology for minimizing our cost function, just like what we were doing with gradient descent in logistic and linear regression. Our goal is to compute:
\begin{equation}
min_{\Theta}J(\Theta)
\end{equation}
\subparagraph{}
That is, we want to minimize our cost function J using an optimal set of parameters in theta. In this section we'll look at the equations we use to compute the partial derivative of $J(\Theta)$:
\begin{equation}
\frac{\partial}{\partial\Theta_{i,j}^{(l)}}J(\Theta)
\end{equation}
\subparagraph{}
To do so, we use the following algorithm:
\begin{figure}[H]
\center{\includegraphics[width=.8\textwidth]{507.png}}
\caption{后向传播算法}
\label{fig:507}
\end{figure}
Given training set {($x^{(1)}$,$y^{(1)}$),($x^{(2)}$,$y^{(2)}$),...,($x^{(m)}$,$y^{(m)}$)}
\subparagraph{}
Set $\Delta_{i,j}^{(l)}:=0$for all (l,i,j), (hence you end up having a matrix full of zeros)
\subparagraph{}
For training example t =1 to m:
\subparagraph{}
（1）Set $a^{(1)}:=x^{(t)}$
\subparagraph{}
（2）Perform forward propagation to compute $a^{(l)}$ for l=2,3,...,L
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{509.png}}
\caption{前向传播算法}
\label{fig:509}
\end{figure}
\subparagraph{}
（3）Using $y^{(t)}$, compute $\delta^{(L)}=a^{(L)}-y^{(t)}$
\subparagraph{}
Where L is our total number of layers and $a^{L}$ is the vector of outputs of the activation units for the last layer. So our "error values" for the last layer are simply the differences of our actual results in the last layer and the correct outputs in y. To get the delta values of the layers before the last layer, we can use an equation that steps us back from right to left:
\subparagraph{}
（4）Compute $\delta^{(L-1)}$,$\delta^{(L-2)}$,...,$\delta^{(2)}$ using $\delta^{(l)}=((\Theta^{(l)})^T\delta^{(l+1)}).* a^{(l)}.*(1-a^{(l)})$
\subparagraph{}
The delta values of layer l are calculated by multiplying the delta values in the next layer with the theta matrix of layer l. We then element-wise multiply that with a function called g', or g-prime, which is the derivative of the activation function g evaluated with the input values given by $z^{(l)}$.
\subparagraph{}
The g-prime derivative terms can also be written out as:
\begin{equation}
g'(z^{(l)})=a^{(l)}.*(1-a^{(l)})
\end{equation}
\subparagraph{}
（5）$\Delta_{i,j}^{(l)}:=\Delta_{i,j}^{(l)}+a_j^{(l)}\delta_i^{(l+1)}$ or with vetorization,$\Delta^{(l)}:=\Delta^{(l)}+\delta^{(l+1)}(a^{(l)})^T$
\subparagraph{}
Hence we update our new Δ matrix.
\begin{align}
D_{ij}^{(l)} & =\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}\quad{if\quad{j\neq0}}\\
D_{ij}^{(l)} & =\frac{1}{m}\Delta_{ij}^{(l)}\qquad{if\quad{j=0}}
\end{align}
\subparagraph{}
The capital-delta matrix D is used as an "accumulator" to add up our values as we go along and eventually compute our partial derivative. Thus we get $\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)=D_{ij}^{(l)}$
\subparagraph{}
Intuition:$\delta_j^{(i)}$="error" of node j in layer l.
\subparagraph{}
$a_j^{(i)}$:第l层第j个单元（节点）的激励值。
\subparagraph{}
我们从最后一层的误差开始计算，误差是激活单元的预测（$a_j^{(4)}$）与实际值（$y_j$）之间的误差，j=1:L。
\subparagraph{}
For each output unit(layer L=4):
\begin{equation}
\delta_j^{(4)}=a_j^{(4)}-y_j
\end{equation}
\subparagraph{}
这里$\delta_j^{(4)}$相当于$(h_\Theta(x))_j$
\subparagraph{}
我们用$\delta$来表示误差，则（向量化）：
\begin{equation}
\delta^{(4)}=a^{(4)}-y
\end{equation}
\subparagraph{}
向量的维度：单元数×1
\subparagraph{}
我们利用这个误差来计算前一层的误差：
\begin{equation}
\delta^{(3)}=(\Theta^{(3)})^T\delta^{(4)}.*g'(z^{(3)})
\end{equation}
\subparagraph{}
其中$g'(z^{(3)})$是S形函数的导数：
\begin{equation}
g'(z^{(3)})=a^{(3)}.*(1-a^{(3)})
\end{equation}
\subparagraph{}
而$(\Theta^{(3)})\delta^{(4)}$则是权重导数的误差的和。
\subparagraph{}
下一步是继续计算第二层的误差：
\begin{equation}
\delta^{(2)}=(\Theta^{(2)})^T\delta^{(3)}.*g'(z^{(2)})
\end{equation}
\subparagraph{}
因为第一层是输入变量，不存在误差。我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设$\lambda=0$，即我们不做任何正则化处理时：
\begin{equation}
\frac{\partial}{\partial\Theta_{ij}^{l}}J(\Theta)=a_j^{(l)}\delta_i^{l+1}
\end{equation}
\subparagraph{}
注释：
\subparagraph{}
l=目前所计算的是第几层；
\subparagraph{}
j=目前计算层中的激活单元的下标，也将是下一层的第j个输入变量的下标；
\subparagraph{}
i=下一层中误差单元的下标，是受到权重矩阵中第i行影响的下一层中的误差单元的下标。
\subparagraph{}
如果考虑正则化处理，并且训练集是一个特征矩阵而非向量。在上面特殊的情况中，我们需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，同样需要计算每一层的误差单元，但是需要为整个训练集计算误差单元，此时的误差单元也是一个矩阵，我们用$\Delta_{ij}^{(l)}$来表示整个误差矩阵。第l层的第i个激活单元受到第j个参数影响而导致的误差。
\subparagraph{}
算法表示：
\begin{figure}[H]
\center{\includegraphics[width=.8\textwidth]{506.png}}
\caption{算法表示}
\label{fig:506}
\end{figure}
\subparagraph{}
即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播算法计算出直至第二层的所有误差。
\subparagraph{}
在求出了$\Delta_{ij}^{(l)}$之后，我们便可以计算低价函数的偏导数了，计算方法如下：
\begin{align}
D_{ij}^{(l)} & =\frac{1}{m}\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)}\quad{if\quad{j\neq0}}\\
D_{ij}^{(l)} & =\frac{1}{m}\Delta_{ij}^{(l)}\qquad{if\quad{j=0}}
\end{align}
\subparagraph{}
在Octave中，如果我们要使用fminuc这样的优化算法来求解出权重矩阵，我们需要将矩阵首先展开成向量，再利用算法求出最优解后再重新转换回矩阵。
\subparagraph{}
假设我们有三个权重矩阵，Theta1，Theat2，Theat3，尺寸分别为和，下面的代码可以实现这样的转换：
\begin{minted}{octave}
thetaVec=[Theta1(:);Theta2(:);Theta3(:)]
...optimization using functions like fminuc...
Theta1=reshape(thetaVec(1:110,10,11));
Theta2=reshape(thetaVec(111:220,10,11));
Theta1=reshape(thetaVec(221:231,1,11));
\end{minted}
\subsection{Backpropagation Intuition}
\subparagraph{}
回顾之前所学的前向传播算法：
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{520.png}}
\caption{回顾前向传播算法}
\label{fig:520}
\end{figure}
\subparagraph{}
Recall that the cost function for a neural network is:
\begin{equation}
J(\Theta)=-\frac{1}{m}\sum_{i=1}^m\sum_{k=1}^K[y_k^{(i)}log((h_\Theta(x^{(i)}))_k)+(1-y_k^{(i)})log(1-(h_\Theta(x^{(i)}))_k)]+\frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_l+1}(\Theta_{j,i}^{(l)})^2
\end{equation}
\subparagraph{}
If we consider simple non-multiclass classification (k = 1) and disregard regularization, the cost is computed with:
\begin{equation}
cost(t)=y^{(t)}log(h_\Theta(x^{(ty)}))+(1-y^{(t)})log(1-h_\Theta(x^{(t)}))
\end{equation}
\subparagraph{}
Intuitively, δj(l) is the "error" for aj(l) (unit j in layer l). More formally, the delta values are actually the derivative of the cost function:
\begin{equation}
\delta_j^{(l)}=\frac{\partial}{\partial{z_j^{(l)}}}cost(t)
\end{equation}
\subparagraph{}
Recall that our derivative is the slope of a line tangent to the cost function, so the steeper the slope the more incorrect we are. Let us consider the following neural network below and see how we could calculate some $\delta_j^{(l)}$:
\subparagraph{}
后向传播算法做的是：
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{521.png}}
\caption{后向传播算法做什么}
\label{fig:521}
\end{figure}
\subparagraph{}
后向传播算法：
\begin{figure}[H]
\center{\includegraphics[width=.8\textwidth]{523.png}}
\caption{后向传播算法}
\label{fig:523}
\end{figure}
\subparagraph{}
In the image above, to calculate $\delta_2^{(2)}$, we multiply the weights $\Theta_{12}^{(2)}$ and $\Theta_{22}^{(2)}$ by their respective $\delta$ values found to the right of each edge. So we get $\delta_2^{(2)}=\Theta_{12}^{(2)}*\delta_1^{(3)}+\Theta_{22}^{(2)}*\delta_2^{(3)}$. To calculate every single possible $\delta_j^{(l)}$, we could start from the right of our diagram. We can think of our edges as our $\Theta_{ij}$. Going from right to left, to calculate the value of $\delta_j^{(l)}$, you can just take the over all sum of each weight times the δ it is coming from. Hence, another example would be $\delta_2^{(3)}=\Theta_{12}^{(3)}*\delta_1^{(4)}$.
\subparagraph{}
练习题：
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{524.png}}
\label{fig:524}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{525.png}}
\caption{后向传播算法习题}
\label{fig:525}
\end{figure}
\section{Backpropagation in Practice}
\subsection{Implementation Note:Unrolling Parameters}
\subparagraph{}
在上一段视频中，我们谈到了怎么使用反向传播算法计算代价函数的导数，在这段视频中，介绍细节的实现过程，怎样把参数从矩阵展开成向量，以便我们在高级最优化步骤中的使用需要。
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{530.png}}
\label{fig:530}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{531.png}}
\label{fig:531}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{535.png}}
\label{fig:535}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{536.png}}
\label{fig:536}
\end{figure}
\subsection{Gradient Checking}
\subparagraph{}
当我们对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能存在一些不容易察觉的错误，意味着，虽然表面看起啦一直在工作，代价看上去不断的减少，但是最终的结果可能并不是最优解。
\subparagraph{}
为了避免这个问题，采取一种叫做梯度的数值检验（Numerical Gradient Checking）的方法，思想是通过估计梯度值来检验我们计算的导数值是否真的是我们要求的。
\subparagraph{}
对梯度的估计方法：在代价函数上沿着切线的方向选择两个非常近的点，然后再计算两个点的平均值，以估计梯度。
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{537.png}}
\caption{梯度检验法}
\label{fig:537}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{538.png}}
\label{fig:538}
\end{figure}
\subparagraph{}
即对于某个特定的$\theta$，我们计算出在$\theta-\epsilon$处和$\theta+\epsilon$的代价函数值（ $\epsilon$ 是一个非常小的值，通常选取0.0001），然后求两个代价的平均，用以估计在$\theta$处的代价值。
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{539.png}}
\caption{向量$\theta$}
\label{fig:539}
\end{figure}
\subparagraph{}
Octave中的代码如下：
\begin{minted}{octave}
gradApprox=(J(theta+eps)-J(theta-eps))/(2*eps)
\end{minted}
\subparagraph{}
当$\theta$是一个向量时,则需要对偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验,下面是一个只针对$\theta_1$进行检验的示例:
\begin{equation}
\frac{\partial}{\partial{\theta_1}}=\frac{j(\theta_1+\epsilon_1,\theta_2,\theta_3,...,\theta_n)-J(\theta_1-\epsilon_1,\theta_2,\theta_3,...,\theta_n)}{2\epsilon}
\end{equation}
\subparagraph{}
We previously saw how to calculate the deltaVector. So once we compute our gradApprox vector, we can check that gradApprox ≈ deltaVector. 
\subparagraph{}
Once you have verified once that your backpropagation algorithm is correct, you don't need to compute gradApprox again. The code to compute gradApprox can be very slow.
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{540.png}}
\label{fig:540}
\end{figure}
\subparagraph{}
最后我们还需要对通过反向传播方法计算出的偏导数进行检验。
\subparagraph{}
根据上面的算法,计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$中。检验时,将该矩阵展开成为向量,同时我们也将$\Theta$矩阵展开为向量,我们针对每一个$\Theta$都计算一个近似的梯度值,将这些值存储于一个近似梯度矩阵中,最终将得出的这个矩阵同$D_{ij}^{(l)}$进行比较。
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{540.png}}
\label{fig:540}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{541.png}}
\label{fig:541}
\end{figure}
\subsection{Random Initialization}
\paragraph{ }
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{550.png}}
\label{fig:550}
\end{figure}
任何优化算法都需要一些初始的参数。到目前为止我们都是初始所有参数为 0,这样的初始方法对于逻辑回归来说是可行的,但是对于神经网络来说是不可行的。如果我们令所有的初始参数都为 0,这将意味着我们第二层的所有激活单元都会有相同的值（对称化）。同理,如果我们初始所有的参数都为一个非 0 的数,结果也是一样的。
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{552.png}}
\label{fig:552}
\end{figure}
\paragraph{}
Initializing all theta weights to zero does not work with neural networks. When we backpropagate, all nodes will update to the same value repeatedly. Instead we can randomly initialize our weights for our Θ matrices using the following method:
通常初始参数为正负 ε 之间的随机值,假设我们要随机初始一个尺寸为 10×11 的参数矩阵,代码如下:
    \begin{minted}{octave}
     Theta1 = rand(10, 11) * (2*eps) - eps
    \end{minted}
\subparagraph{}
Hence, we initialize each $\Theta_{ij}^{(l)}$ to a random value between $[-\epsilon,\epsilon]$. Using the above formula guarantees that we get the desired bound. The same procedure applies to all the $\Theta$'s. Below is some working code you could use to experiment.
\begin{figure}[H]
\center{\includegraphics[width=.8\textwidth]{559.png}}
\label{fig:559}
\end{figure}
\subparagraph{}
rand(x,y) is just a function in octave that will initialize a matrix of random real numbers between 0 and 1.
\subparagraph{}
(Note: the epsilon used above is unrelated to the epsilon from Gradient Checking)
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{553.png}}
\label{fig:553}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{556.png}}
\label{fig:556}
\end{figure}
\subsection{Putting it Together}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{560.png}}
\caption{训练神经网络}
\label{fig:560}
\end{figure}
使用神经网络的步骤：
\paragraph{}
网络结构：第一件要做的事是选择网络结构，即决定选择多少层以及决定每层分别有多少个单元。
\paragraph{}
第一层的单元数即是我们训练集的特征数量。
\paragraph{}
最后一层的单元数是我们训练集的结果的类的数量。
\paragraph{}
如果隐藏层数大于1，确保每个隐藏层的单元个数相同，通常情况下隐藏层单元的个数越多越好。
\paragraph{}
我们真正要决定的是隐藏层的层数和每个中间层的单元数。
\subparagraph{}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{561.png}}
\label{fig:561}
\end{figure}
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{562.png}}
\caption{训练神经网络步骤}
\label{fig:562}
\end{figure}
\subparagraph{}
注意：$J(\Theta)$是一个non-convex函数（非凸函数），理论上都能都优化到最小值。
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{570.png}}
\caption{神经网络的梯度下降算法的实现}
\label{fig:570}
\end{figure}
\subparagraph{}
Ideally, you want $h_\Theta(x^{(i)})\approx{y^{(i)}}$. This will minimize our cost function. However, keep in mind that $J(\Theta)$ is not convex and thus we can end up in a local minimum instead. 
\begin{figure}[H]
\center{\includegraphics[width=.6\textwidth]{571.png}}
\label{fig:571}
\end{figure}
\subparagraph{}
训练神经网络的步骤：
\subparagraph{}
（1）参数的随机初始化
\subparagraph{}
（2）利用正向传播方法计算所有的$h_\Theta(x)$
\subparagraph{}
（3）编写计算代价函数$J(\Theta)$的代码
\subparagraph{}
（4）利用反向传播算法计算所有偏导数
\subparagraph{}
（5）利用数值检验方法检验这些偏导数
\subparagraph{}
（6）使用优化算法来最小化代价函数
\section{Application of Neural Networks}
\subsection{Autonomous Driving}
\subparagraph{}
在这段视频中,我想向你介绍一个具有历史意义的神经网络学习的重要例子。那就是使
用神经网络来实现自动驾驶,也就是说使汽车通过学习来自己驾驶。接下来我将演示的这段
视频是我从 Dean Pomerleau 那里拿到的,他是我的同事,任职于美国东海岸的卡耐基梅隆大学。在这部分视频中,你就会明白可视化技术到底是什么?在看这段视频之前,我会告诉你可视化技术是什么。
\subparagraph{}
在下面也就是左下方,就是汽车所看到的前方的路况图像。
\begin{figure}[H]
\center{\includegraphics[width=.4\textwidth]{5555.png}}
\label{fig:5555}
\end{figure}
\subparagraph{}
在图中你依稀能看出一条道路,朝左延伸了一点,又向右了一点,然后上面的这幅图,
你可以看到一条水平的菜单栏显示的是驾驶操作人选择的方向。就是这里的这条白亮的区段
显示的就是人类驾驶者选择的方向。比如:最左边的区段,对应的操作就是向左急转,而最
右端则对应向右急转的操作。因此,稍微靠左的区段,也就是中心稍微向左一点的位置,则
表示在这一点上人类驾驶者的操作是慢慢的向左拐。
\subparagraph{}
这幅图的第二部分对应的就是学习算法选出的行驶方向。并且,类似的,这一条白亮的
区段显示的就是神经网络在这里选择的行驶方向,是稍微的左转,并且实际上在神经网络开
始学习之前,你会看到网络的输出是一条灰色的区段,就像这样的一条灰色区段覆盖着整个
区域这些均称的灰色区域,显示出神经网络已经随机初始化了,并且初始化时,我们并不知
道汽车如何行驶,或者说我们并不知道所选行驶方向。只有在学习算法运行了足够长的时间
之后,才会有这条白色的区段出现在整条灰色区域之中。显示出一个具体的行驶方向这就表
示神经网络算法,在这时候已经选出了一个明确的行驶方向,不像刚开始的时候,输出一段
模糊的浅灰色区域,而是输出一条白亮的区段,表示已经选出了明确的行驶方向。
\begin{figure}[H]
\center{\includegraphics[width=.4\textwidth]{5557.png}}
\label{fig:5557}
\end{figure}
\subparagraph{}
ALVINN (Autonomous Land Vehicle In a Neural Network)是一个基于神经网络的智能系统,通过观察人类的驾驶来学习驾驶,ALVINN 能够控制 NavLab,装在一辆改装版军用悍马,这辆悍马装载了传感器、计算机和驱动器用来进行自动驾驶的导航试验。实现 ALVINN 功能的第一步,是对它进行训练,也就是训练一个人驾驶汽车。
\begin{figure}[H]
\center{\includegraphics[width=.4\textwidth]{5556.png}}
\label{fig:5556}
\end{figure}
\subparagraph{}
然后让 ALVINN 观看,ALVINN 每两秒将前方的路况图生成一张数字化图片,并且记录驾
驶者的驾驶方向,得到的训练集图片被压缩为 30x32 像素,并且作为输入提供给 ALVINN 的三层神经网络,通过使用反向传播学习算法,ALVINN 会训练得到一个与人类驾驶员操纵方向基本相近的结果。一开始,我们的网络选择出的方向是随机的,大约经过两分钟的训练后,我们的神经网络便能够准确地模拟人类驾驶者的驾驶方向,对其他道路类型,也重复进行这个训练过程,当网络被训练完成后,操作者就可按下运行按钮,车辆便开始行驶了。
\begin{figure}[H]
\center{\includegraphics[width=.4\textwidth]{5558.png}}
\label{fig:5558}
\end{figure}
\subparagraph{}
每秒钟 ALVINN 生成 12 次数字化图片,并且将图像传送给神经网络进行训练,多个神经
网络同时工作,每一个网络都生成一个行驶方向,以及一个预测自信度的参数,预测自信度
最高的那个神经网络得到的行驶方向。比如这里,在这条单行道上训练出的网络将被最终用
于控制车辆方向,车辆前方突然出现了一个交叉十字路口,当车辆到达这个十字路口时,我
们单行道网络对应的自信度骤减,当它穿过这个十字路口时,前方的双车道将进入其视线,
双车道网络的自信度便开始上升,当它的自信度上升时 双车道的网络,将被选择来控制行
驶方向,车辆将被安全地引导进入双车道路。
\subparagraph{}
这就是基于神经网络的自动驾驶技术。当然,我们还有很多更加先进的试验来实现自动
驾驶技术。在美国,欧洲等一些国家和地区,他们提供了一些比这个方法更加稳定的驾驶控
制技术。但我认为,使用这样一个简单的基于反向传播的神经网络,训练出如此强大的自动
驾驶汽车,的确是一次令人惊讶的成就。
\end{CJK}
\end{document}